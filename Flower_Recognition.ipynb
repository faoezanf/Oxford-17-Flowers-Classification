{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower Recognition.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7LQ3T01wGFL"
      },
      "source": [
        "<b> Fauzan Firdaus (23520011)<br> \n",
        "Nadya Aditama (23520039) </b>\n",
        "\n",
        "# Flower Recognition Experiment\n",
        "Pada notebook ini, akan dilakukan eksperimen mengenai rekognisi citra bunga dengan membandingkan deskriptor fitur ekstraksi gabungan dengan arsitektur model CNN.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Deskripsi Singkat Dataset\n",
        "![CaptureFlower](https://user-images.githubusercontent.com/15353477/98227599-14368f80-1f8a-11eb-9af1-549adb75746f.PNG)\n",
        "Dataset yang digunakan adalah dataset **Oxford 17 Flower**, terdiri dari 1**7 spesies**, dimana setiap spesies terdiri dari **80 citra**, sehingga total datasetnya adalah **1.360 citra**. Karakteristik data tersebut adalah sebagai berikut\n",
        "\n",
        "\n",
        "*   Citra memiliki ukuran yang bervariasi, namun perbedaan ukurannya tidak jauh (kisaran 500-800 piksel).\n",
        "*   Skala citra bervariasi (portrait, landscape, dan square).\n",
        "*   Posture dan lightning dari citra bervariasi.\n",
        "*   Dalam satu citra bisa terdiri dari lebih dari satu bunga.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPaGfMtExMg0"
      },
      "source": [
        "## Import Package\n",
        "Berikut ini adalah package yang dibutuhkan untuk eksperimen ini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IZVfA2awdOp",
        "outputId": "4e58fbf4-8d1a-4ea0-9a7f-449a16894558"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI_nntjKwGk1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import scipy\n",
        "from IPython import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from skimage.feature import hog\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhYpIjR1xECA"
      },
      "source": [
        "# 1. Descriptor Ekstraksi Fitur\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ILiAOXew-2R"
      },
      "source": [
        "## Load Image Data\n",
        "Sebelum dilakukan load data, file citra dikategorikan dalam folder berdasarkan kelas. Kemudian di-load dengan code berikut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4--AGhbw_Uk",
        "outputId": "855e0abd-62a1-4c5c-ab77-8941e26b44ba"
      },
      "source": [
        "DATADIR=\"gdrive/My Drive/Tugas Pattern Recognition/Tugas 1/17flowers\"\n",
        "CATEGORIES=[\"Bluebell\",\"Buttercup\",\"ColtsFoot\",\n",
        "            \"Cowslip\",\"Crocus\",\"Daffodils\",\n",
        "            \"Daisy\",\"Dandelion\",\"Fritillary\",\n",
        "            \"Iris\",\"LilyValley\",\"Pansy\",\n",
        "            \"Snowdrop\",\"Sunflower\",\"Tigerlily\",\n",
        "            \"Tulip\",\"Wildflower\"]\n",
        "training_data=[]\n",
        "i = 1\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR,category)\n",
        "    class_num=CATEGORIES.index(category)\n",
        "    for img in os.listdir(path):\n",
        "        try:\n",
        "            img_array=cv2.imread(os.path.join(path,img))\n",
        "            new_image=np.asarray(cv2.resize(img_array,(300,300)))\n",
        "            training_data.append([new_image, class_num])\n",
        "            print(\"Gambar termuat : \",i)\n",
        "            display.clear_output(wait=True)\n",
        "            i=i+1\n",
        "        except Exception as e:\n",
        "            pass## Load Image Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gambar termuat :  1360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TN0MRAmxWSY"
      },
      "source": [
        "## Split Train and Test Data\n",
        "Dataset dibagi sebesar 80% data latih dan 20% data uji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U17jbekaxZCR"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "for image,label in training_data:\n",
        "    X.append(image)\n",
        "    y.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCTA74YgzVUi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42,stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd9AapbszYaW"
      },
      "source": [
        "Jumlah data latih dan data uji adalah sebagai berikut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LONNmmuvzY41",
        "outputId": "60254f2f-ec32-4b5f-f1ea-d479b28440c1"
      },
      "source": [
        "print(\"Jumlah data latih : \",np.shape(X_train)[0])\n",
        "print(\"Jumlah data uji   : \",np.shape(X_test)[0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah data latih :  1088\n",
            "Jumlah data uji   :  272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU9ya8iFzgrC"
      },
      "source": [
        "## Preprocessing\n",
        "Fitur yang akan dilihat dalam pengenalan citra bunga adalah fitur warna, bentuk, dan tekstur. Preprocessing yang dilakukan dalam citra tersebut adalah sebagai berikut\n",
        "1.   Konversi ruang warna RGB ke Grayscale\n",
        "2.   Konversi ruang warna RGB ke HSV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKo1ASYFzhVv"
      },
      "source": [
        "def preprocessing1(arr):\n",
        "    arr_prep=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        img=cv2.cvtColor(arr[i], cv2.COLOR_BGR2GRAY)\n",
        "        arr_prep.append(img)\n",
        "    return arr_prep\n",
        "\n",
        "def preprocessing2(arr):\n",
        "    arr_prep=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        image=cv2.cvtColor(arr[i], cv2.COLOR_BGR2GRAY)\n",
        "        arr_prep.append(image)\n",
        "    return arr_prep\n",
        "\n",
        "def preprocessing3(arr):\n",
        "    arr_prep=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        image=cv2.cvtColor(arr[i], cv2.COLOR_BGR2HSV)\n",
        "        arr_prep.append(image)\n",
        "    return arr_prep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWwxG7uEz_Qi"
      },
      "source": [
        "## Feature Extraction\n",
        "Metode ekstraksi fitur yang digunakan dalam eksperimen ini adalah sebagai berikut\n",
        "1.   HOG (Histogram of Oriented Gradient) sebagai deskriptor bentuk.\n",
        "2.   GLCM (Gray Level Co-occurrence Matrix) sebagai deskriptor tesktur\n",
        "3.   YCBcr (Color Histogram dari YCBcr) sebagai deskriptor warna\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXtyZ-3G0ARG"
      },
      "source": [
        "def FtrExtractHOG(img):\n",
        "    ftr,_=hog(img, orientations=9, pixels_per_cell=(50, 50),\n",
        "            cells_per_block=(2, 2), visualize=True, multichannel=False, block_norm= 'L2')\n",
        "    return ftr\n",
        "\n",
        "def FtrExtractGLCM(img, props, dists=[5], agls=[0, np.pi/4, np.pi/2, 3*np.pi/4], lvl=256, sym=True, norm=True):\n",
        "    glcm = greycomatrix(img, \n",
        "                        distances=dists, \n",
        "                        angles=agls, \n",
        "                        levels=lvl,\n",
        "                        symmetric=sym, \n",
        "                        normed=norm)\n",
        "    feature = []\n",
        "    glcm_props = [propery for name in props for propery in greycoprops(glcm, name)[0]]\n",
        "    for item in glcm_props:\n",
        "            feature.append(item)\n",
        "        \n",
        "    return feature\n",
        "\n",
        "def FtrExtractHSV(img):\n",
        "    chans = cv2.split(img)\n",
        "    features = []\n",
        "\n",
        "    for chan in chans:\n",
        "        hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\n",
        "        features.extend(hist)\n",
        "    return np.array(features).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwHtK0in0eMs"
      },
      "source": [
        "def featureExtraction1(arr):\n",
        "    arr_feature=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        arr_feature.append(FtrExtractHOG(arr[i]))\n",
        "    return arr_feature\n",
        "\n",
        "properties = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']\n",
        "def featureExtraction2(arr):\n",
        "    arr_feature=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        arr_feature.append(FtrExtractGLCM(arr[i],props=properties))\n",
        "    return arr_feature\n",
        "\n",
        "def featureExtraction3(arr):\n",
        "    arr_feature=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        arr_feature.append(FtrExtractHSV(arr[i]))\n",
        "    return arr_feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uokXtsgD1n56"
      },
      "source": [
        "## K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekLo6bIMTVel"
      },
      "source": [
        "Validasi yang dilakukan menggunakan metode K-fold cross validation dengan K sebesar 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfrJZyOp1qz_"
      },
      "source": [
        "def kfold_1(X_train,y_train,K,stat):\n",
        "\n",
        "  cvscores = []\n",
        "  i = 1\n",
        "  skf = KFold(n_splits=K)\n",
        "\n",
        "  X_train_ = np.array(X_train)\n",
        "  y_train = np.array(y_train)\n",
        "  if (stat==1):\n",
        "      RF = RandomForestClassifier(n_estimators=400, random_state = 42)\n",
        "      for train_index,val_index in skf.split(X_train_):\n",
        "        x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "        y_train_new,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "        RF.fit(x_train_new, y_train_new)\n",
        "\n",
        "        y_pred = RF.predict(x_val)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        print(\"Fold ke\",i,\" -> \",end=\" \")\n",
        "        print(\"%.3f%%\"%(acc*100))\n",
        "        i=i+1\n",
        "        cvscores.append(acc)\n",
        "  elif (stat==2):\n",
        "      DTL = DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=20, random_state=42)\n",
        "      for train_index,val_index in skf.split(X_train_):\n",
        "        x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "        y_train_new,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "        DTL.fit(x_train_new, y_train_new)\n",
        "\n",
        "        y_pred = DTL.predict(x_val)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        print(\"Fold ke\",i,\" -> \",end=\" \")\n",
        "        print(\"%.3f%%\"%(acc*100))\n",
        "        i=i+1\n",
        "        cvscores.append(acc)\n",
        "  elif (stat==3):\n",
        "      XG = xgb.XGBClassifier(subsample=0.8, learning_rate=0.1)\n",
        "      for train_index,val_index in skf.split(X_train_):\n",
        "        x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "        y_train_new,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "        XG.fit(x_train_new, y_train_new)\n",
        "\n",
        "        y_pred = XG.predict(x_val)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        print(\"Fold ke\",i,\" -> \",end=\" \")\n",
        "        print(\"%.3f%%\"%(acc*100))\n",
        "        i=i+1\n",
        "        cvscores.append(acc)\n",
        "  \n",
        "  return cvscores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L3X2h6K0lhh"
      },
      "source": [
        "Preprocessing terhadap masing-masing jenis ekstraksi fitur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJIKXal_0j6C"
      },
      "source": [
        "X_trainp_shape=preprocessing1(X_train)\n",
        "X_testp_shape=preprocessing1(X_test)\n",
        "\n",
        "X_trainp_texture=preprocessing2(X_train)\n",
        "X_testp_texture=preprocessing2(X_test)\n",
        "\n",
        "X_trainp_color=preprocessing3(X_train)\n",
        "X_testp_color=preprocessing3(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBG50wIu0upd"
      },
      "source": [
        "Ekstraksi fitur bentuk, tekstur, dan warna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7_Ka_GH0wA3"
      },
      "source": [
        "X_trainftr_shape=featureExtraction1(X_trainp_shape)\n",
        "X_testftr_shape=featureExtraction1(X_testp_shape)\n",
        "\n",
        "X_trainftr_texture=featureExtraction2(X_trainp_texture)\n",
        "X_testftr_texture=featureExtraction2(X_testp_texture)\n",
        "\n",
        "X_trainftr_color=featureExtraction3(X_trainp_color)\n",
        "X_testftr_color=featureExtraction3(X_testp_color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhzZCg3T0zO9"
      },
      "source": [
        "X_trainftr_combined = np.concatenate((X_trainftr_shape,X_trainftr_texture,X_trainftr_color),axis=1)\n",
        "X_testftr_combined = np.concatenate((X_testftr_shape,X_testftr_texture,X_testftr_color),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAjIgW3901_n"
      },
      "source": [
        "Ukuran dimensi fitur citra adalah sebagai berikut "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18uIHrN303_f",
        "outputId": "bd7323ce-c715-4fde-932c-2913ec1eec06"
      },
      "source": [
        "print(\"Dimensi fitur bentuk  : \",np.shape(X_trainftr_shape)[1])\n",
        "print(\"Dimensi fitur tekstur : \",np.shape(X_trainftr_texture)[1])\n",
        "print(\"Dimensi fitur warna   : \",np.shape(X_trainftr_color)[1])\n",
        "print(\"Dimensi fitur gabungan: \",np.shape(X_trainftr_combined)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensi fitur bentuk  :  900\n",
            "Dimensi fitur tekstur :  24\n",
            "Dimensi fitur warna   :  768\n",
            "Dimensi fitur gabungan:  1692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyI9JY2j1K7U"
      },
      "source": [
        "## Random Forest (RF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yorxplKi5oFA",
        "outputId": "d7553916-ce52-4361-e652-bd8da8cc1979"
      },
      "source": [
        "RFValidation = kfold_1(X_trainftr_combined,y_train,5,1)\n",
        "print(\"Akurasi Validasi RF : %.3f%%\" % (np.average(RFValidation)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold ke 1  ->  58.716%\n",
            "Fold ke 2  ->  64.220%\n",
            "Fold ke 3  ->  61.468%\n",
            "Fold ke 4  ->  67.742%\n",
            "Fold ke 5  ->  55.760%\n",
            "Akurasi Validasi RF : 61.581%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8Zvl5N61NT0",
        "outputId": "496fcf9a-6a2a-4091-e80c-307a12467117"
      },
      "source": [
        "RF = RandomForestClassifier(n_estimators=400, random_state = 42)\n",
        "RF.fit(X_trainftr_combined, y_train)\n",
        "y_pred_RF = RF.predict(X_testftr_combined)\n",
        "print(\"Akurasi Testing RF : %.3f%%\"% (accuracy_score(y_test, y_pred_RF)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi Testing RF : 66.176%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLP3JJGBTznx"
      },
      "source": [
        "Berikut adalah metrics evaluation dari Random Forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8F5Y-g6ZF94",
        "outputId": "0fb25d49-4006-4456-b131-e9159046f4b4"
      },
      "source": [
        "print(classification_report(y_test, y_pred_RF))\n",
        "print(confusion_matrix(y_test, y_pred_RF))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.75      0.69        16\n",
            "           1       0.69      0.69      0.69        16\n",
            "           2       0.88      0.44      0.58        16\n",
            "           3       0.44      0.50      0.47        16\n",
            "           4       0.71      0.62      0.67        16\n",
            "           5       0.69      0.56      0.62        16\n",
            "           6       0.71      0.94      0.81        16\n",
            "           7       0.85      0.69      0.76        16\n",
            "           8       0.79      0.94      0.86        16\n",
            "           9       0.75      0.56      0.64        16\n",
            "          10       0.56      0.62      0.59        16\n",
            "          11       0.72      0.81      0.76        16\n",
            "          12       0.58      0.44      0.50        16\n",
            "          13       0.62      0.81      0.70        16\n",
            "          14       0.62      0.81      0.70        16\n",
            "          15       0.50      0.31      0.38        16\n",
            "          16       0.63      0.75      0.69        16\n",
            "\n",
            "    accuracy                           0.66       272\n",
            "   macro avg       0.67      0.66      0.65       272\n",
            "weighted avg       0.67      0.66      0.65       272\n",
            "\n",
            "[[12  0  0  0  0  0  0  0  0  0  2  2  0  0  0  0  0]\n",
            " [ 0 11  0  1  0  0  0  0  0  1  0  1  0  1  1  0  0]\n",
            " [ 0  1  7  0  0  1  2  0  1  0  0  0  1  2  0  1  0]\n",
            " [ 1  0  0  8  1  0  0  0  0  0  2  0  0  0  1  3  0]\n",
            " [ 1  0  0  0 10  0  1  0  0  0  1  0  2  0  1  0  0]\n",
            " [ 0  1  0  1  1  9  1  0  1  1  0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  1 15  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  1  0 11  0  0  0  0  0  3  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 15  0  0  0  0  0  1  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  1  9  0  1  1  0  0  1  2]\n",
            " [ 1  0  0  1  1  0  0  0  1  0 10  0  0  0  1  0  1]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  2 13  0  0  0  0  0]\n",
            " [ 2  0  0  1  0  0  0  0  0  0  0  0  7  0  2  0  4]\n",
            " [ 0  0  0  0  0  0  0  2  0  0  0  0  0 13  1  0  0]\n",
            " [ 0  0  0  1  0  0  1  0  0  0  0  0  0  1 13  0  0]\n",
            " [ 0  2  0  5  1  1  0  0  0  1  0  0  0  1  0  5  0]\n",
            " [ 0  1  0  0  0  0  1  0  0  0  1  1  0  0  0  0 12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbAEAj9c1ONq"
      },
      "source": [
        "## Decision Tree Learning (DTL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mzRGoiF1Rua",
        "outputId": "03462a91-d9fa-4483-ea1a-49090073b16d"
      },
      "source": [
        "DTLValidation = kfold_1(X_trainftr_combined,y_train,5,2)\n",
        "print(\"Akurasi Validasi DTL : %.3f%%\" % (np.average(DTLValidation)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold ke 1  ->  29.817%\n",
            "Fold ke 2  ->  40.826%\n",
            "Fold ke 3  ->  30.275%\n",
            "Fold ke 4  ->  39.631%\n",
            "Fold ke 5  ->  30.876%\n",
            "Akurasi Validasi DTL : 34.285%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWQgmv45AaOA",
        "outputId": "e05ca9e9-3af7-45e0-a443-e00d085e3a4b"
      },
      "source": [
        "DTL = DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=20, random_state=42)\n",
        "DTL.fit(X_trainftr_combined, y_train)\n",
        "y_pred_DTL = DTL.predict(X_testftr_combined)\n",
        "print(\"Akurasi Testing DTL : %.3f%%\"% (accuracy_score(y_test, y_pred_DTL)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi Testing DTL : 35.294%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O09QWA_1UBP-"
      },
      "source": [
        "Berikut adalah metrics evaluation dari Decision Tree Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf4tGrQkZNaB",
        "outputId": "b92f2002-ec3d-4601-877c-87c3f680d157"
      },
      "source": [
        "print(classification_report(y_test, y_pred_DTL))\n",
        "print(confusion_matrix(y_test, y_pred_DTL))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.44      0.45        16\n",
            "           1       0.50      0.56      0.53        16\n",
            "           2       0.20      0.19      0.19        16\n",
            "           3       0.15      0.12      0.14        16\n",
            "           4       0.43      0.38      0.40        16\n",
            "           5       0.36      0.25      0.30        16\n",
            "           6       0.75      0.56      0.64        16\n",
            "           7       0.42      0.31      0.36        16\n",
            "           8       0.73      0.50      0.59        16\n",
            "           9       0.26      0.38      0.31        16\n",
            "          10       0.50      0.62      0.56        16\n",
            "          11       0.32      0.38      0.34        16\n",
            "          12       0.12      0.12      0.12        16\n",
            "          13       0.33      0.38      0.35        16\n",
            "          14       0.21      0.38      0.27        16\n",
            "          15       0.07      0.06      0.07        16\n",
            "          16       0.50      0.38      0.43        16\n",
            "\n",
            "    accuracy                           0.35       272\n",
            "   macro avg       0.37      0.35      0.36       272\n",
            "weighted avg       0.37      0.35      0.36       272\n",
            "\n",
            "[[ 7  0  1  0  1  0  0  0  0  1  0  3  2  0  1  0  0]\n",
            " [ 0  9  0  1  0  1  0  0  0  1  1  1  0  0  0  2  0]\n",
            " [ 0  0  3  1  0  2  1  1  0  1  0  0  1  5  1  0  0]\n",
            " [ 0  0  2  2  0  0  0  1  0  0  2  1  3  2  1  2  0]\n",
            " [ 2  1  0  0  6  0  0  0  0  1  0  3  2  0  1  0  0]\n",
            " [ 0  2  1  1  0  4  0  0  0  1  0  0  0  2  3  2  0]\n",
            " [ 0  0  0  1  0  0  9  2  0  1  1  0  1  0  0  1  0]\n",
            " [ 0  1  3  1  0  1  0  5  0  2  1  0  0  2  0  0  0]\n",
            " [ 0  0  0  0  4  0  0  0  8  0  0  0  0  0  4  0  0]\n",
            " [ 1  0  0  2  1  0  0  0  1  6  0  2  0  0  1  0  2]\n",
            " [ 1  0  0  0  1  0  0  0  0  0 10  0  2  0  2  0  0]\n",
            " [ 4  1  0  0  1  0  0  0  0  1  0  6  2  0  0  1  0]\n",
            " [ 0  1  1  0  0  0  0  0  1  2  1  0  2  0  2  2  4]\n",
            " [ 0  1  1  0  0  1  0  1  0  1  0  1  0  6  3  1  0]\n",
            " [ 0  1  1  0  0  0  1  1  1  1  1  1  0  0  6  2  0]\n",
            " [ 0  1  2  4  0  2  0  1  0  1  1  0  0  1  2  1  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  3  2  1  1  0  2  0  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msOy3QxT1TvG"
      },
      "source": [
        "## XGBoost (XGB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC06JKsW1Wep",
        "outputId": "3ac70545-ae28-4f9a-e890-2399eb5818af"
      },
      "source": [
        "XGValidation = kfold_1(X_trainftr_combined,y_train,5,3)\n",
        "print(\"Akurasi Validasi XGB : %.3f%%\" % (np.average(XGValidation)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold ke 1  ->  61.468%\n",
            "Fold ke 2  ->  68.807%\n",
            "Fold ke 3  ->  65.596%\n",
            "Fold ke 4  ->  70.507%\n",
            "Fold ke 5  ->  53.917%\n",
            "Akurasi Validasi XGB : 64.059%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aZHuMVhA1uI",
        "outputId": "a1629409-d159-4300-c4c0-e91b472959f9"
      },
      "source": [
        "XG = xgb.XGBClassifier(subsample=0.8, learning_rate=0.1)\n",
        "XG.fit(X_trainftr_combined, y_train)\n",
        "y_pred_XG = XG.predict(X_testftr_combined)\n",
        "print(\"Akurasi Testing XG : %.3f%%\"%(accuracy_score(y_test, y_pred_XG)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi Testing XG : 69.485%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK7KAUOIUIoe"
      },
      "source": [
        "Berikut adalah metrics evaluation dari XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfG-3o8sZQjL",
        "outputId": "8ac526f4-88a7-4b07-ba65-13330f3f3551"
      },
      "source": [
        "print(classification_report(y_test, y_pred_XG))\n",
        "print(confusion_matrix(y_test, y_pred_XG))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.94      0.73        16\n",
            "           1       0.75      0.75      0.75        16\n",
            "           2       0.69      0.69      0.69        16\n",
            "           3       0.47      0.56      0.51        16\n",
            "           4       0.62      0.50      0.55        16\n",
            "           5       0.82      0.56      0.67        16\n",
            "           6       0.83      0.94      0.88        16\n",
            "           7       0.92      0.75      0.83        16\n",
            "           8       0.87      0.81      0.84        16\n",
            "           9       1.00      0.75      0.86        16\n",
            "          10       0.53      0.62      0.57        16\n",
            "          11       0.87      0.81      0.84        16\n",
            "          12       0.77      0.62      0.69        16\n",
            "          13       0.73      0.69      0.71        16\n",
            "          14       0.53      0.62      0.57        16\n",
            "          15       0.40      0.38      0.39        16\n",
            "          16       0.72      0.81      0.76        16\n",
            "\n",
            "    accuracy                           0.69       272\n",
            "   macro avg       0.71      0.69      0.70       272\n",
            "weighted avg       0.71      0.69      0.70       272\n",
            "\n",
            "[[15  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
            " [ 0 12  1  1  0  0  0  1  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  1 11  0  0  0  0  0  0  0  0  0  0  2  0  2  0]\n",
            " [ 1  0  1  9  0  0  0  0  0  0  2  0  0  0  1  2  0]\n",
            " [ 1  0  0  0  8  0  2  0  0  0  0  1  1  0  1  1  1]\n",
            " [ 0  1  0  1  1  9  1  0  0  0  0  0  1  0  0  2  0]\n",
            " [ 0  0  0  0  0  1 15  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  2  0  0  0  0 12  0  0  0  0  0  2  0  0  0]\n",
            " [ 2  0  0  0  0  0  0  0 13  0  0  0  0  0  1  0  0]\n",
            " [ 2  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  2]\n",
            " [ 1  0  0  0  2  0  0  0  0  0 10  0  0  0  2  1  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  2 13  0  0  0  0  0]\n",
            " [ 2  0  0  0  0  0  0  0  0  0  0  0 10  0  2  0  2]\n",
            " [ 0  1  0  1  0  0  0  0  0  0  0  0  0 11  2  1  0]\n",
            " [ 0  0  1  3  0  0  0  0  0  0  1  0  1  0 10  0  0]\n",
            " [ 0  1  0  4  1  1  0  0  1  0  2  0  0  0  0  6  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  2  0  0  0  0  0 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNr5EvdxGd9s"
      },
      "source": [
        "# 2. Arsitektur CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqvsF7jFUMeG"
      },
      "source": [
        "Normalisasi Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJpYXYyHHI7Z"
      },
      "source": [
        "X_train = np.array(X_train).astype('float32')\n",
        "X_test = np.array(X_test).astype('float32')\n",
        "\n",
        "mean_image = np.mean(X_train, axis = 0)\n",
        "\n",
        "X_train -= mean_image\n",
        "X_test -= mean_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGRddfLpHL1P"
      },
      "source": [
        "y_train_binary = to_categorical(y_train)\n",
        "y_test_binary = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZziUEA3GlzN"
      },
      "source": [
        "## 2.a Inception-V3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCFPrYNqURBx"
      },
      "source": [
        "Buat model inception tanpa pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh28r9IMHYfE"
      },
      "source": [
        "def create_inception_model():\n",
        "  model = InceptionV3(weights=None, include_top=False, input_shape=(300,300,3), pooling='max')\n",
        "  x = model.output\n",
        "  predictions = Dense(17, activation='softmax')(x)\n",
        "  myModel_scratch = Model(inputs=model.input, outputs=predictions, name='InceptionV3')\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  myModel_scratch.compile(optimizer=opt,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return myModel_scratch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1YRWtHQUYQw"
      },
      "source": [
        "Validasi dengan 5-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeg7vQ0LIBKb"
      },
      "source": [
        "def kfold_2(X_train,y_train,K):\n",
        "\n",
        "  model_validation=create_inception_model()\n",
        "  cvscores = []\n",
        "  i = 1\n",
        "  skf = KFold(n_splits=K)\n",
        "\n",
        "  X_train_ = np.array(X_train)\n",
        "  y_train = np.array(y_train)\n",
        "  for train_index,val_index in skf.split(X_train_):\n",
        "    x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "    y_train_new,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "    model_validation.fit(x_train_new, y_train_new, validation_data = (x_val,y_val), epochs=20, verbose=0)\n",
        "\n",
        "    scores = model_validation.evaluate(x_val, y_val, verbose=0)\n",
        "    # print(\"Fold ke\",i,\" -> \",scores[1]*100,\"%\")\n",
        "    print(\"Fold ke\",i,\" -> \",end=\" \")\n",
        "    print(\"%.3f%%\"%(scores[1]*100))\n",
        "    i=i+1\n",
        "    cvscores.append(scores[1])\n",
        "\n",
        "  return cvscores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzmENVxkHi7V",
        "outputId": "07473fac-02c6-4a33-d982-22bcb3b7afe1"
      },
      "source": [
        "inception_validation = kfold_2(X_train,y_train_binary,5)\n",
        "print(\"Akurasi Validasi CNN-Inception : %.3f%%\" % (np.average(inception_validation)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold ke 1  ->  53.670%\n",
            "Fold ke 2  ->  65.596%\n",
            "Fold ke 3  ->  86.239%\n",
            "Fold ke 4  ->  84.332%\n",
            "Fold ke 5  ->  91.244%\n",
            "Akurasi Validasi CNN-Inception : 76.216%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK81DdyYUcyC"
      },
      "source": [
        "Lakukan training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F6_S1OyP0Vo",
        "outputId": "40bca6d2-80c0-4b2b-b25d-a3620d3b5066"
      },
      "source": [
        "model = create_inception_model()\n",
        "model.fit(X_train, y_train_binary,epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 2/34 [>.............................] - ETA: 11s - loss: 4.6960 - accuracy: 0.0156   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1733s vs `on_train_batch_end` time: 0.2660s). Check your callbacks.\n",
            "34/34 [==============================] - 15s 444ms/step - loss: 2.9902 - accuracy: 0.1489\n",
            "Epoch 2/20\n",
            "34/34 [==============================] - 16s 457ms/step - loss: 2.1834 - accuracy: 0.3511\n",
            "Epoch 3/20\n",
            "34/34 [==============================] - 16s 462ms/step - loss: 1.8543 - accuracy: 0.4072\n",
            "Epoch 4/20\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 1.6758 - accuracy: 0.4669\n",
            "Epoch 5/20\n",
            "34/34 [==============================] - 15s 444ms/step - loss: 1.4516 - accuracy: 0.5460\n",
            "Epoch 6/20\n",
            "34/34 [==============================] - 15s 446ms/step - loss: 1.3648 - accuracy: 0.5653\n",
            "Epoch 7/20\n",
            "34/34 [==============================] - 15s 454ms/step - loss: 1.2827 - accuracy: 0.5892\n",
            "Epoch 8/20\n",
            "34/34 [==============================] - 15s 451ms/step - loss: 1.1273 - accuracy: 0.6406\n",
            "Epoch 9/20\n",
            "34/34 [==============================] - 15s 448ms/step - loss: 0.9941 - accuracy: 0.6700\n",
            "Epoch 10/20\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 0.9541 - accuracy: 0.6838\n",
            "Epoch 11/20\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 0.8707 - accuracy: 0.7188\n",
            "Epoch 12/20\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 0.7315 - accuracy: 0.7684\n",
            "Epoch 13/20\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 0.7121 - accuracy: 0.7895\n",
            "Epoch 14/20\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 0.6268 - accuracy: 0.8024\n",
            "Epoch 15/20\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 0.5558 - accuracy: 0.8244\n",
            "Epoch 16/20\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 0.4508 - accuracy: 0.8493\n",
            "Epoch 17/20\n",
            "34/34 [==============================] - 15s 448ms/step - loss: 0.4230 - accuracy: 0.8778\n",
            "Epoch 18/20\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 0.3165 - accuracy: 0.9053\n",
            "Epoch 19/20\n",
            "34/34 [==============================] - 15s 449ms/step - loss: 0.2520 - accuracy: 0.9366\n",
            "Epoch 20/20\n",
            "34/34 [==============================] - 15s 450ms/step - loss: 0.2405 - accuracy: 0.9403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55feb4af28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR9qWEKmUfPK"
      },
      "source": [
        "Berikut adalah metrics evaluation dari Inception-V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4jFyEGhQV2V",
        "outputId": "1cad55a6-11e7-4b6a-c4c8-8c1b6c6ddcaa"
      },
      "source": [
        "predictions = model.predict(X_test , batch_size = 32).argmax(axis = 1)\n",
        "print(classification_report(y_test_binary.argmax(axis = 1), predictions))\n",
        "print(confusion_matrix(y_test_binary.argmax(axis = 1), predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.88      0.76        16\n",
            "           1       0.74      0.88      0.80        16\n",
            "           2       0.62      0.31      0.42        16\n",
            "           3       0.33      0.25      0.29        16\n",
            "           4       0.55      0.38      0.44        16\n",
            "           5       0.70      0.44      0.54        16\n",
            "           6       0.79      0.69      0.73        16\n",
            "           7       0.61      0.69      0.65        16\n",
            "           8       0.75      0.94      0.83        16\n",
            "           9       0.68      0.81      0.74        16\n",
            "          10       0.71      0.62      0.67        16\n",
            "          11       0.58      0.88      0.70        16\n",
            "          12       0.70      0.44      0.54        16\n",
            "          13       0.56      0.56      0.56        16\n",
            "          14       1.00      0.56      0.72        16\n",
            "          15       0.38      0.56      0.45        16\n",
            "          16       0.65      0.94      0.77        16\n",
            "\n",
            "    accuracy                           0.64       272\n",
            "   macro avg       0.65      0.64      0.62       272\n",
            "weighted avg       0.65      0.64      0.62       272\n",
            "\n",
            "[[14  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0]\n",
            " [ 0 14  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
            " [ 0  1  5  0  0  0  0  4  0  1  0  0  0  4  0  1  0]\n",
            " [ 0  1  0  4  0  1  0  1  0  0  0  1  0  0  0  7  1]\n",
            " [ 4  0  1  0  6  0  0  0  0  1  0  2  2  0  0  0  0]\n",
            " [ 0  2  0  1  1  7  0  1  0  0  0  0  0  0  0  3  1]\n",
            " [ 0  0  0  0  0  0 11  0  0  0  1  0  0  0  0  0  4]\n",
            " [ 0  0  1  0  0  0  0 11  1  0  0  0  0  2  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0 15  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  1  0  0  0 13  0  1  0  0  0  0  0]\n",
            " [ 1  0  0  0  1  0  1  0  1  0 10  0  1  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0 14  0  0  0  0  1]\n",
            " [ 2  0  0  0  1  0  1  0  1  1  1  1  7  0  0  1  0]\n",
            " [ 0  1  1  1  0  0  0  0  0  1  0  3  0  9  0  0  0]\n",
            " [ 0  0  0  1  1  0  0  1  0  2  0  1  0  0  9  1  0]\n",
            " [ 0  0  0  4  0  1  0  0  1  0  0  0  0  1  0  9  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJXJ_urKQfq-",
        "outputId": "5824e4a1-56fb-4388-9387-d7bca62a70d4"
      },
      "source": [
        "accuracy = model.evaluate(X_test, y_test_binary, verbose=1)\n",
        "print('Test loss    :', accuracy[0])\n",
        "print('Test accuracy: %.2f%%' % (accuracy[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 109ms/step - loss: 1.2583 - accuracy: 0.6360\n",
            "Test loss    : 1.2583361864089966\n",
            "Test accuracy: 63.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1TW5LtRGvGH"
      },
      "source": [
        "## 2.b Custom Architecture (Model sendiri)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsxLCwxcROH4"
      },
      "source": [
        "def create_model(lr = 0.0001):\n",
        "  model = Sequential([\n",
        "      Conv2D(32,(3,3),input_shape=(300,300,3), padding='same', activation=\"relu\"),\n",
        "      Conv2D(32,(3,3), padding='same', activation=\"relu\"),\n",
        "      MaxPooling2D(3,3),\n",
        "      Conv2D(64,(3,3), padding='same', activation=\"relu\"),\n",
        "      Conv2D(64,(3,3), padding='same', activation=\"relu\"),\n",
        "      MaxPooling2D(3,3),\n",
        "      Conv2D(128,(3,3), padding='same', activation=\"relu\"),\n",
        "      Conv2D(256,(3,3), padding='same', activation=\"relu\"),\n",
        "      MaxPooling2D(3,3),\n",
        "      Conv2D(256,(3,3), padding='same', activation=\"relu\"),\n",
        "      Flatten(),\n",
        "      Dense(1024, activation=\"relu\"),\n",
        "      Dropout(0.5),\n",
        "      Dense(512, activation=\"relu\"),\n",
        "      Dense(17, activation=\"softmax\")\n",
        "  ])\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po3mBjAlU4Vd"
      },
      "source": [
        "Lakukan 5-fold cross validation dengan berbeda-beda learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJGvr4d7SMDZ",
        "outputId": "5ab2e6cd-3669-42a1-f60d-753cde601818"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "cvscores = []\n",
        "model_param = [0,0,0,0,0,0]\n",
        "n_split=5\n",
        "\n",
        "i = 1\n",
        "\n",
        "X_train_ = np.array(X_train)\n",
        "for train_index,val_index in KFold(n_split).split(X_train_):\n",
        "  x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "  y_train_new,y_val=y_train_binary[train_index],y_train_binary[val_index]\n",
        "\n",
        "  lr_score=[]\n",
        "  print(\"Fold ke \",i)\n",
        "  learning_rate = [0.1,0.01,0.001,0.0001,0.00001,0.000001]\n",
        "  j=0\n",
        "  for lr in learning_rate:\n",
        "    #simpen model dengan learning rate masing2\n",
        "    model_param[j]=create_model(lr=lr)\n",
        "    model_param[j].fit(x_train_new, y_train_new, validation_data = (x_val,y_val), epochs=20, verbose=0)\n",
        "\n",
        "    #ngambil score\n",
        "    scores = model_param[j].evaluate(x_val, y_val, verbose=0)\n",
        "    print('learning rate ',lr,\"= %.2f%%\" % (scores[1]*100))\n",
        "    lr_score.append(scores[1]*100)\n",
        "    j=j+1\n",
        "\n",
        "  i=i+1\n",
        "  cvscores.append(lr_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold ke  1\n",
            "learning rate  0.1 = 5.05%\n",
            "learning rate  0.01 = 1.83%\n",
            "learning rate  0.001 = 47.71%\n",
            "learning rate  0.0001 = 63.76%\n",
            "learning rate  1e-05 = 51.38%\n",
            "learning rate  1e-06 = 27.06%\n",
            "Fold ke  2\n",
            "learning rate  0.1 = 5.05%\n",
            "learning rate  0.01 = 4.59%\n",
            "learning rate  0.001 = 48.62%\n",
            "learning rate  0.0001 = 63.30%\n",
            "learning rate  1e-05 = 60.55%\n",
            "learning rate  1e-06 = 26.15%\n",
            "Fold ke  3\n",
            "learning rate  0.1 = 5.96%\n",
            "learning rate  0.01 = 3.67%\n",
            "learning rate  0.001 = 47.25%\n",
            "learning rate  0.0001 = 62.84%\n",
            "learning rate  1e-05 = 56.42%\n",
            "learning rate  1e-06 = 20.64%\n",
            "Fold ke  4\n",
            "learning rate  0.1 = 5.53%\n",
            "learning rate  0.01 = 3.69%\n",
            "learning rate  0.001 = 40.55%\n",
            "learning rate  0.0001 = 62.67%\n",
            "learning rate  1e-05 = 56.22%\n",
            "learning rate  1e-06 = 29.95%\n",
            "Fold ke  5\n",
            "learning rate  0.1 = 5.07%\n",
            "learning rate  0.01 = 3.23%\n",
            "learning rate  0.001 = 48.39%\n",
            "learning rate  0.0001 = 58.06%\n",
            "learning rate  1e-05 = 48.85%\n",
            "learning rate  1e-06 = 21.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7R-HEpoSXiQ",
        "outputId": "e8017315-56c2-4214-d3d4-0060b9559c93"
      },
      "source": [
        "print(\"----------------- Rata-rata Seluruhnya ----------------------\")\n",
        "print(\"learning rate 0.1     = %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores, axis=0)[0], np.std(cvscores, axis=0)[0])) \n",
        "print(\"learning rate 0.01    = %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores, axis=0)[1], np.std(cvscores, axis=0)[1]))\n",
        "print(\"learning rate 0.001   = %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores, axis=0)[2], np.std(cvscores, axis=0)[2]))\n",
        "print(\"learning rate 0.0001  = %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores, axis=0)[3], np.std(cvscores, axis=0)[3]))\n",
        "print(\"learning rate 0.00001   = %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores, axis=0)[4], np.std(cvscores, axis=0)[4]))\n",
        "print(\"learning rate 0.000001  = %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores, axis=0)[5], np.std(cvscores, axis=0)[5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Rata-rata Seluruhnya ----------------------\n",
            "learning rate 0.1     = 5.33% (+/- 0.37%)\n",
            "learning rate 0.01    = 3.40% (+/- 0.90%)\n",
            "learning rate 0.001   = 46.50% (+/- 3.02%)\n",
            "learning rate 0.0001  = 62.13% (+/- 2.07%)\n",
            "learning rate 0.00001   = 54.68% (+/- 4.12%)\n",
            "learning rate 0.000001  = 25.00% (+/- 3.57%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiJw9sDOSrBG"
      },
      "source": [
        "modelfixed = model_param[3]\n",
        "\n",
        "predictions = modelfixed.predict(X_test , batch_size = 32).argmax(axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gjLxEjrSxb2",
        "outputId": "b90246d0-d4ce-4159-9f0f-dd48b98821c2"
      },
      "source": [
        "print('Model evaluation ',modelfixed.evaluate(X_test,y_test_binary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 42ms/step - loss: 1.5640 - accuracy: 0.6434\n",
            "Model evaluation  [1.5639725923538208, 0.6433823704719543]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6etz25eS0PN"
      },
      "source": [
        "model_predict = modelfixed.predict(X_test)\n",
        "class_id = np.argmax(model_predict,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOnNeW36VHLB"
      },
      "source": [
        "Berikut adalah metrics evaluation dari arsitektur CNN model yang kami bangun."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKtUlxfJTG42",
        "outputId": "3d5a44ab-b9ba-40a9-88e2-9390c7b03c3e"
      },
      "source": [
        "print(classification_report(y_test_binary.argmax(axis = 1), predictions))\n",
        "print(confusion_matrix(y_test_binary.argmax(axis = 1), predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      1.00      0.62        16\n",
            "           1       0.64      0.88      0.74        16\n",
            "           2       0.53      0.56      0.55        16\n",
            "           3       0.62      0.31      0.42        16\n",
            "           4       0.62      0.31      0.42        16\n",
            "           5       0.86      0.38      0.52        16\n",
            "           6       0.71      0.75      0.73        16\n",
            "           7       0.73      0.69      0.71        16\n",
            "           8       1.00      0.50      0.67        16\n",
            "           9       1.00      0.81      0.90        16\n",
            "          10       0.59      0.81      0.68        16\n",
            "          11       1.00      0.69      0.81        16\n",
            "          12       0.42      0.50      0.46        16\n",
            "          13       0.67      0.62      0.65        16\n",
            "          14       0.70      1.00      0.82        16\n",
            "          15       0.38      0.31      0.34        16\n",
            "          16       0.72      0.81      0.76        16\n",
            "\n",
            "    accuracy                           0.64       272\n",
            "   macro avg       0.68      0.64      0.63       272\n",
            "weighted avg       0.68      0.64      0.63       272\n",
            "\n",
            "[[16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0]\n",
            " [ 0  1  9  0  0  0  0  2  0  0  0  0  0  3  0  1  0]\n",
            " [ 0  1  2  5  0  0  0  0  0  0  4  0  1  0  0  3  0]\n",
            " [ 5  0  0  0  5  0  1  0  0  0  0  0  3  0  1  0  1]\n",
            " [ 0  2  2  1  0  6  2  0  0  0  1  0  0  0  0  2  0]\n",
            " [ 2  0  0  0  0  0 12  0  0  0  0  0  1  0  0  0  1]\n",
            " [ 0  1  1  0  0  0  0 11  0  0  0  0  0  2  1  0  0]\n",
            " [ 5  0  0  0  2  0  0  0  8  0  0  0  1  0  0  0  0]\n",
            " [ 1  0  0  0  0  1  1  0  0 13  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 13  0  3  0  0  0  0]\n",
            " [ 4  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  1]\n",
            " [ 2  0  2  0  0  0  0  0  0  0  2  0  8  0  0  0  2]\n",
            " [ 0  1  1  1  0  0  0  1  0  0  0  0  0 10  2  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0]\n",
            " [ 1  2  0  1  1  0  0  1  0  0  0  0  2  0  3  5  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  2  0  0  0  0  0 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjNxsmL9I9nt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}